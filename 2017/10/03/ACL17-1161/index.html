<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="baidu-site-verification" content="rlXUrNbP8h" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="论文链接：P17-1161
摘要
从未标注文本中学习到的预训练词向量已经成为NLP任务神经网络结构的重要组成部分。但是大多数情况下，现在的循环神经网络还是从极少的标注数据中学习上下文相关的表示。所以这篇论文研究一种通用的半监督学习方法，将从双向语言模型中预训练出来的词向量加到NLP系统中，把它应用到序列标注任务中。我们在两个NLP任务上做实验：NER和chunking。
1 介绍
这篇论文我...">
    <meta name="keyword"  content="ECNU NLP DeepLearning">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <title>
        
          Semi-supervised sequence tagging with bidirectional language models - WeiYang Blog | 韦阳的博客
        
    </title>

    <link rel="canonical" href="https://godweiyang.com/2017/10/03/ACL17-1161/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS --> 
    <link rel="stylesheet" href="/css/beantech.min.css">
    
    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css">

    <link rel="stylesheet" href="/css/widget.css">

    <link rel="stylesheet" href="/css/rocket.css">

    <link rel="stylesheet" href="/css/signature.css">

    <link rel="stylesheet" href="/css/toc.css">

    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
    
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?46e79e71af0709a5b9106bf20cecc493";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            background-image: url('header.jpg')
            /*post*/
        
    }
    
    #signature{
        background-image: url('/img/signature/BeanTechSign-white.png');
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#ACL" title="ACL">ACL</a>
                            
                              <a class="tag" href="/tags/#NLP" title="NLP">NLP</a>
                            
                              <a class="tag" href="/tags/#神经网络" title="神经网络">神经网络</a>
                            
                              <a class="tag" href="/tags/#深度学习" title="深度学习">深度学习</a>
                            
                        </div>
                        <h1>Semi-supervised sequence tagging with bidirectional language models</h1>
                        <h2 class="subheading">基于双向语言模型的半监督序列标注</h2>
                        <span class="meta">
                            Posted by WeiYang on
                            2017-10-03
                        </span>
                    </div>
                


                </div>
            </div>
        </div>
    </div>
    
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?46e79e71af0709a5b9106bf20cecc493";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">WeiYang Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Modify by Yu-Hsuan Yen -->

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <p>论文链接：<a href="https://www.aclweb.org/anthology/P/P17/P17-1161.pdf" target="_blank" rel="external">P17-1161</a></p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><hr>
<p>从未标注文本中学习到的预训练词向量已经成为NLP任务神经网络结构的重要组成部分。<br>但是大多数情况下，现在的循环神经网络还是从极少的标注数据中学习上下文相关的表示。<br>所以这篇论文研究一种通用的半监督学习方法，将从双向语言模型中预训练出来的词向量加到NLP系统中，把它应用到序列标注任务中。<br>我们在两个NLP任务上做实验：NER和chunking。</p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h1><hr>
<p>这篇论文我们探讨一种半监督学习方法，不需要额外的标注数据。<br>我们使用一个神经语言模型，在大量未标注数据上训练，计算出每个位置上下文的编码，然后应用到半监督的标注模型中。<br>我们第一个主要贡献是证明了语言模型训练出的上下文相关表示在半监督标注模型中是很有用的。<br>第二个贡献是多使用一个后向的语言模型效果更好。<br>同时我们发现没必要针对某个领域数据来专门训练。</p>
<h1 id="2-语言模型增强的序列标注"><a href="#2-语言模型增强的序列标注" class="headerlink" title="2 语言模型增强的序列标注"></a>2 语言模型增强的序列标注</h1><hr>
<h3 id="2-1-概览"><a href="#2-1-概览" class="headerlink" title="2.1 概览"></a>2.1 概览</h3><p>这个模型的主要结构如图所示：<br><img src="/2017/10/03/ACL17-1161/1.jpg" data-action="zoom"><br>主要过程可以分为3步：</p>
<ul>
<li>首先在大量的未标注数据上训练词向量和一个神经语言模型</li>
<li>然后提取一个句子中每个单词的词向量表示与语言模型表示</li>
<li>最后将它们应用到监督序列标注模型中。</li>
</ul>
<p>具体的结构如下图所示：<br><img src="/2017/10/03/ACL17-1161/2.jpg" data-action="zoom"></p>
<h3 id="2-2-基本的序列标注模型"><a href="#2-2-基本的序列标注模型" class="headerlink" title="2.2 基本的序列标注模型"></a>2.2 基本的序列标注模型</h3><p>我们用到的基本的序列标注模型是一个分层的神经序列标注模型，如上图左半部分所示。<br>给定一个句子\(({t_1},{t_2}, \ldots ,{t_N})\)，首先对于每个单词\({t_k}\)产生一个表示\({x_k}\)，其中\({x_k}\)是由这个单词基于字符的表示\({c_k}\)和词向量表示\({w_k}\)连接而成：<br>\[\begin{array}{l}{c_k} = C({t_k};{\theta _c})\\{w_k} = E({t_k};{\theta _w})\\{x_k} = [{c_k};{w_k}]\end{array}\]字符表示\({c_k}\)捕获的是这个单词的形态信息，可以用CNN或者RNN来实现。<br>词向量表示\({w_k}\)是从预训练的词向量表中直接提取的。<br>为了学习到上下文相关的表示，我们采用多层双向RNN。<br>对于每个单词\({x_k}\)，第\({i}\)层隐含层\({h_{k,i}}\)是由前向隐含层状态\({ {\vec h}_{k,i}}\)和后向隐含层状态\({ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k,i}}\)连接而成。<br>对于第一层隐含层，\({h_{k,1}}\)由\({x_k}\)经过如下运算获得：<br>\[\begin{array}{l}{ {\vec h}_{k,1}} = { {\vec R}_1}({x_k},{ {\vec h}_{k - 1,1}};{\theta _{ { {\vec R}_1}}})\\{ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k,1}} = { {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over R} }_1}({x_k},{ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k + 1,1}};{\theta _{ { {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over R} }_1}}})\\{h_{k,1}} = [{ {\vec h}_{k,1}};{ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k,1}}]\end{array}\]这个实验中我们使用2层隐含层，并且使用GRU或者LSTM作为双向RNN。<br>最后，最后一层隐含层的输出\({h_{k,L}}\)被输出到一个稠密层，用来预测每个标签的评分。<br>由于在我们的序列标注任务中，连续的标签之间是有依赖性的，所以联合起来预测一整个句子的标签比单独预测每个单词的标签更好。<br>因此，我们增加了额外的一层来计算相邻两个标签之间的条件随机场损失，然后用Viterbi算法来寻找概率最大的标签序列。</p>
<h3 id="2-3-双向语言模型"><a href="#2-3-双向语言模型" class="headerlink" title="2.3 双向语言模型"></a>2.3 双向语言模型</h3><p>一个语言模型是用来计算一个句子\(({t_1},{t_2}, \ldots ,{t_N})\)的概率：<br>\[p({t_1},{t_2}, \ldots ,{t_N}) = \prod\limits_{k - 1}^N {p({t_k}|{t_1},{t_2}, \ldots ,{t_{k - 1}})} \]之前的研究将每个单词的字符表示或者词向量表示送到多层LSTM中，用\(({t_1},{t_2}, \ldots ,{t_k})\)来求出隐含层\({ {\vec h}^{LM}}_k\)，这就是第\(k\)个单词的前向语言模型表示，同时也是语言模型LSTM层最顶端的输出。最后用softmax层来预测\({t_{k + 1}}\)的概率。<br>当然再加上一个后向语言模型表示效果就更好了：<br>\[p({t_1},{t_2}, \ldots ,{t_N}) = \prod\limits_{k - 1}^N {p({t_k}|{t_{k + 1}},{t_{k + 2}}, \ldots ,{t_N})} \]后向语言模型表示实现方式和前向相似，产生输出\({ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }^{LM}}_k\)<br>注意到在这个模型中，前向后向语言模型是独立的，不共享任何参数。</p>
<h3 id="2-4-结合语言模型和序列模型"><a href="#2-4-结合语言模型和序列模型" class="headerlink" title="2.4 结合语言模型和序列模型"></a>2.4 结合语言模型和序列模型</h3><p>我们结合的模型TagLM是将语言模型的词表示当作额外的输入传送到序列标注模型中。<br>在实验中，我们发现将语言模型表示和序列模型第一层隐含层输出结合效果最好。表示如下：<br>\[{h_{k,1}} = [{ {\vec h}_{k,1}};{ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k,1}};{h_k}^{LM}]\]有许多方法可以结合语言模型表示和序列模型第一层隐含层输出，比如用一个非线性函数来结合：<br>\[{h_{k,1}} = f([{ {\vec h}_{k,1}};{ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k,1}};{h_k}^{LM}])\]另一种可能的方法是用类似注意力模型的机制，给每个单词的语言模型表示加上权重，然后再加进序列模型中。<br>本次实验中直接结合效果已经很好了，所以没有尝试其他方法。</p>
<h1 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a>3 实验</h1><hr>
<p>我们在两个NLP任务上做实验：NER和chunking，使用F1评价指标和BIOES标注体系。<br>我们对数据做了预处理，对所有字母小写处理，将所有数字替换成0。</p>
<h4 id="CoNLL-2003-NER"><a href="#CoNLL-2003-NER" class="headerlink" title="CoNLL 2003 NER"></a>CoNLL 2003 NER</h4><p>CoNLL 2003 NER任务包含了路透社RCV1语料库，它是由4种不同的实体类型标注的：PER、LOC、ORG、MISC，包含了标准的训练集、验证集和测试集。<br>我们的序列模型的字符表示使用了80个隐含层和25维字符表示的双向GRU。上面的序列层使用了两个300个隐含层的双向GRU。为了正则化，每个GRU的输入都添加了25%的dropout。</p>
<h4 id="CoNLL-2000-chunking"><a href="#CoNLL-2000-chunking" class="headerlink" title="CoNLL 2000 chunking"></a>CoNLL 2000 chunking</h4><p>CoNLL 2000 chunking任务使用华尔街日报第15~18章训练，第20章测试。定义了11种句法分块类型，我们从训练集随机标记出1000个句子作为验证集。<br>序列模型字符表示使用了30维字符表示和带有30个宽度为3字符滤波器的CNN。上面的序列层使用了两个200个隐含层的双向GRU。每个GRU的输入都添加了50%的dropout。</p>
<h4 id="预训练语言模型"><a href="#预训练语言模型" class="headerlink" title="预训练语言模型"></a>预训练语言模型</h4><p>我们在1B Word Benchmark上面训练语言模型，包含了8亿个单词。<br>我们使用两个2048个单元，512维的LSTM，在4个GPU上进行参数的同步更新，在10轮训练后就停止训练。</p>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>所有的实验都采用Adam优化器在5.0处进行梯度截断。<br>提前结束训练来防止过拟合，采用以下方法来决定什么时候停止训练：开始时学习率设为0.001，观察验证集每一轮的性能，当验证集上的性能达到最高时，将学习率降低一个数量级，再训练5次，再降低一个数量级，再训练5次，最后停止训练。</p>
<h3 id="3-1-综合系统结果"><a href="#3-1-综合系统结果" class="headerlink" title="3.1 综合系统结果"></a>3.1 综合系统结果</h3><p>表1和表2比较的是TagLM和其他没有额外标注数据的模型结果。<br>表3和表4比较的是TagLM和其他包含额外标注数据的模型结果。<br><img src="/2017/10/03/ACL17-1161/3.jpg" data-action="zoom"><br><img src="/2017/10/03/ACL17-1161/4.jpg" data-action="zoom"></p>
<ul>
<li>增加外部标注数据<br>尽管我们没有使用外部标注数据，但是我们效果依然比其他模型要好。表3和表4还可以看出这个模型加了语言模型后的提升是最大的。</li>
</ul>
<h3 id="3-2-分析"><a href="#3-2-分析" class="headerlink" title="3.2 分析"></a>3.2 分析</h3><p>为了解释我们的TagLM的特性，我们在CoNLL 2003 NER上做了许多额外的实验。</p>
<h4 id="怎样使用语言模型表示？"><a href="#怎样使用语言模型表示？" class="headerlink" title="怎样使用语言模型表示？"></a>怎样使用语言模型表示？</h4><p>在这个实验中，我们将语言模型产生的表示连接到序列模型的不同位置：</p>
<ul>
<li>连接到第一个RNN的输入层：<br>\[{x_k} = [{c_k};{w_k};{h_k}^{LM}]\]</li>
<li>连接到第一个RNN的输出层：<br>\[{h_{k,1}} = [{ {\vec h}_{k,1}};{ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k,1}};{h_k}^{LM}]\]</li>
<li>连接到第二个RNN的输出层：<br>\[{h_{k,2}} = [{ {\vec h}_{k,2}};{ {\mathord{\buildrel{\lower3pt\hbox{$\scriptscriptstyle\leftarrow$}} \over h} }_{k,2}};{h_k}^{LM}]\]</li>
</ul>
<p>表5显示出第二种位置是效果最好的，我们猜测原因可能是因为第二层RNN可以捕获第一层RNN产生的任务特定的上下文和语言模型产生的通用的上下文之间的互相联系。<br><img src="/2017/10/03/ACL17-1161/5.jpg" data-action="zoom"></p>
<h4 id="用哪一种语言模型重要吗？"><a href="#用哪一种语言模型重要吗？" class="headerlink" title="用哪一种语言模型重要吗？"></a>用哪一种语言模型重要吗？</h4><p>从表6可以看出，前向传播使用CNN-BIG-LSTM，后向传播使用LSTM-2048-512效果是最好的，但是我们没有测试后向也是CNN-BIG-LSTM的，那样效果估计会更好。<br><img src="/2017/10/03/ACL17-1161/6.jpg" data-action="zoom"></p>
<h4 id="任务特定RNN的重要性"><a href="#任务特定RNN的重要性" class="headerlink" title="任务特定RNN的重要性"></a>任务特定RNN的重要性</h4><p>我们把任务特定的RNN去掉了，只用语言模型和稠密层和CRF来预测输出标签，结果非常的差。说明还是需要任务特定RNN来对标注数据编码产生必要的信息的。</p>
<h4 id="数据集的大小"><a href="#数据集的大小" class="headerlink" title="数据集的大小"></a>数据集的大小</h4><p>通过在大数据和小数据上做实验，得出如下结论：<br>以往的模型在小数据上从无语言模型到有语言模型提升都是很大的，但是在大数据上提升就非常的少了。<br>而我们的TagLM不论是小数据还是大数据性能提升都非常的大。</p>
<h4 id="参数个数"><a href="#参数个数" class="headerlink" title="参数个数"></a>参数个数</h4><p>由于第二层RNN的输入加入了语言模型表示，所以维数增加了，但是对实验效果几乎没有影响的。<br>我们通过两个实验来验证：</p>
<ul>
<li>增加不包含语言模型的序列模型的第二层RNN维数。</li>
<li>减少TagLM的第二层RNN维数。</li>
</ul>
<p>性能提升都非常的少，而且还说明了TagLM增加的参数对性能是有略微削弱的。</p>
<h4 id="语言模型要跟随语料库领域而改变吗？"><a href="#语言模型要跟随语料库领域而改变吗？" class="headerlink" title="语言模型要跟随语料库领域而改变吗？"></a>语言模型要跟随语料库领域而改变吗？</h4><p>答案是不需要，之前都是在新闻语料上做的训练，我们直接把它应用到了科技语料库上，性能依然有很大提升。</p>
<h1 id="4-相关工作"><a href="#4-相关工作" class="headerlink" title="4 相关工作"></a>4 相关工作</h1><hr>
<h4 id="未标注数据"><a href="#未标注数据" class="headerlink" title="未标注数据"></a>未标注数据</h4><h4 id="神经语言模型"><a href="#神经语言模型" class="headerlink" title="神经语言模型"></a>神经语言模型</h4><h4 id="解释RNN状态"><a href="#解释RNN状态" class="headerlink" title="解释RNN状态"></a>解释RNN状态</h4><h4 id="其他序列标注模型"><a href="#其他序列标注模型" class="headerlink" title="其他序列标注模型"></a>其他序列标注模型</h4><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><hr>
<ul>
<li>提出了一种简单、通用的半监督方法，使用预训练的神经语言模型，来给序列标注模型增加上下文表示。</li>
<li>我们的方法在NER和chunking任务上比其他的方法都要好。</li>
<li>多使用一个后向的语言模型效果更好。</li>
<li>即使语言模型在不同领域的语料库上训练，或者序列模型在大数据量的标注数据上训练，效果依然有很大提升。</li>
</ul>


                <br />
                <div class="social-share" align="center" data-sites="qzone,qq,weibo,wechat" data-wechat-qrcode-title="请打开微信扫一扫分享" data-wechat-qrcode-helper=""></div>
                <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
                <script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>

                <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
                <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
                <div id="gitalk-container"></div>     <script type="text/javascript">
                    var gitalk = new Gitalk({
                        clientID: 'c3ac6e20697ee5422b43',
                        clientSecret: '3ccf19d2ec7e33b55f71aaeec74542a3938772f6',
                        repo: 'godweiyang.github.io',
                        owner: 'godweiyang',
                        admin: ['godweiyang'],
                        id: '2017/10/03/ACL17-1161/',
                        distractionFreeMode: true,
                    });
                    gitalk.render('gitalk-container');
                </script>


                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/2017/10/25/ACL17-2027/" data-toggle="tooltip" data-placement="top" title="Implicitly-Defined Neural Networks for Sequence Labeling">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/2017/10/02/sublime/" data-toggle="tooltip" data-placement="top" title="Sublime Text安装与配置教程">Next Post &rarr;</a>
                        </li>
                    
                </ul>
                <p></p>

            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#摘要"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">摘要</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#1-介绍"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">1 介绍</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#2-语言模型增强的序列标注"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">2 语言模型增强的序列标注</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-1-概览"><span class="toc-nav-number">3.0.1.</span> <span class="toc-nav-text">2.1 概览</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-2-基本的序列标注模型"><span class="toc-nav-number">3.0.2.</span> <span class="toc-nav-text">2.2 基本的序列标注模型</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-3-双向语言模型"><span class="toc-nav-number">3.0.3.</span> <span class="toc-nav-text">2.3 双向语言模型</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-4-结合语言模型和序列模型"><span class="toc-nav-number">3.0.4.</span> <span class="toc-nav-text">2.4 结合语言模型和序列模型</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#3-实验"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">3 实验</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#CoNLL-2003-NER"><span class="toc-nav-number">4.0.0.1.</span> <span class="toc-nav-text">CoNLL 2003 NER</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#CoNLL-2000-chunking"><span class="toc-nav-number">4.0.0.2.</span> <span class="toc-nav-text">CoNLL 2000 chunking</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#预训练语言模型"><span class="toc-nav-number">4.0.0.3.</span> <span class="toc-nav-text">预训练语言模型</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#训练"><span class="toc-nav-number">4.0.0.4.</span> <span class="toc-nav-text">训练</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-1-综合系统结果"><span class="toc-nav-number">4.0.1.</span> <span class="toc-nav-text">3.1 综合系统结果</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#3-2-分析"><span class="toc-nav-number">4.0.2.</span> <span class="toc-nav-text">3.2 分析</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#怎样使用语言模型表示？"><span class="toc-nav-number">4.0.2.1.</span> <span class="toc-nav-text">怎样使用语言模型表示？</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#用哪一种语言模型重要吗？"><span class="toc-nav-number">4.0.2.2.</span> <span class="toc-nav-text">用哪一种语言模型重要吗？</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#任务特定RNN的重要性"><span class="toc-nav-number">4.0.2.3.</span> <span class="toc-nav-text">任务特定RNN的重要性</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#数据集的大小"><span class="toc-nav-number">4.0.2.4.</span> <span class="toc-nav-text">数据集的大小</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#参数个数"><span class="toc-nav-number">4.0.2.5.</span> <span class="toc-nav-text">参数个数</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#语言模型要跟随语料库领域而改变吗？"><span class="toc-nav-number">4.0.2.6.</span> <span class="toc-nav-text">语言模型要跟随语料库领域而改变吗？</span></a></li></ol></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#4-相关工作"><span class="toc-nav-number">5.</span> <span class="toc-nav-text">4 相关工作</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#未标注数据"><span class="toc-nav-number">5.0.0.1.</span> <span class="toc-nav-text">未标注数据</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#神经语言模型"><span class="toc-nav-number">5.0.0.2.</span> <span class="toc-nav-text">神经语言模型</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#解释RNN状态"><span class="toc-nav-number">5.0.0.3.</span> <span class="toc-nav-text">解释RNN状态</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#其他序列标注模型"><span class="toc-nav-number">5.0.0.4.</span> <span class="toc-nav-text">其他序列标注模型</span></a></li></ol></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#5-总结"><span class="toc-nav-number">6.</span> <span class="toc-nav-text">5 总结</span></a></li></ol>
        
        </div>
      </aside>
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#ACL" title="ACL">ACL</a>
                        
                          <a class="tag" href="/tags/#NLP" title="NLP">NLP</a>
                        
                          <a class="tag" href="/tags/#神经网络" title="神经网络">神经网络</a>
                        
                          <a class="tag" href="/tags/#深度学习" title="深度学习">深度学习</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="https://sweet-q.github.io" target="_blank">babyQ</a></li>
                    
                        <li><a href="http://blog.csdn.net/cww97" target="_blank">cww97</a></li>
                    
                        <li><a href="https://www.dreamwings.cn/" target="_blank">dreamwings</a></li>
                    
                        <li><a href="https://www.elainelv.top/" target="_blank">elainelv</a></li>
                    
                        <li><a href="https://www.gofun4.top/" target="_blank">Fun4wut</a></li>
                    
                        <li><a href="http://haelchan.me/" target="_blank">Hael&#39;s Blog</a></li>
                    
                        <li><a href="http://hzwer.com/" target="_blank">hzwer</a></li>
                    
                        <li><a href="https://angericky.github.io/" target="_blank">Jingjing&#39;s blog</a></li>
                    
                        <li><a href="https://www.jxtxzzw.com/wordpress" target="_blank">jxtxzzw空间</a></li>
                    
                        <li><a href="https://blog.csdn.net/MIKASA3" target="_blank">kewlgrl</a></li>
                    
                        <li><a href="http://jiaqianlee.com/" target="_blank">LJQ&#39;s Blog</a></li>
                    
                        <li><a href="https://chrisqiqiang.com/" target="_blank">Qi Qiang</a></li>
                    
                        <li><a href="https://xuzhongyou.github.io/" target="_blank">xuzhongyou</a></li>
                    
                        <li><a href="http://liyucheng.info/" target="_blank">Yucheng Li</a></li>
                    
                        <li><a href="http://zerol.me/" target="_blank">zerol</a></li>
                    
                        <li><a href="http://codewithzhangyi.com/" target="_blank">Zhang Yi</a></li>
                    
                        <li><a href="https://spaces.ac.cn/" target="_blank">科学空间</a></li>
                    
                        <li><a href="http://www.navazil.com/" target="_blank">孙哥我还是看不透生死</a></li>
                    
                        <li><a href="http://www.itaowei.cn/" target="_blank">望城风景</a></li>
                    
                        <li><a href="https://chrisju.cn/" target="_blank">咸鱼的自我修养</a></li>
                    
                        <li><a href="http://blog.sina.com.cn/u/5848707168" target="_blank">隐函数_北极鹅</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>


<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!--  <script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>  -->
<style>
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


<script type="text/javascript" src="/js/zooming.js"></script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>


    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/godweiyang">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/godweiyang">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="http://weibo.com/godweiyang">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://user.qzone.qq.com/792321264">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-qq fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; WeiYang 2019 
                </p>
                <p class="copyright text-muted">
                    <!-- <a target="_blank" title="web analytic"><img alt="web analytic" src="http://monster.gostats.com/bin/count/a_494843/t_4/i_38/z_0/show_visitors/counter.png" style="border-width:0" /></a> -->
                    <!-- <a><img alt="web trackers" src="http://monster.gostats.com/bin/count/a_494843/t_4/i_38/z_0/show_visitors/counter.png" 
                    style="border-width:0"/></a> -->
                    <a><img border="0" src="https://cc.amazingcounters.com/counter.php?i=3221735&c=9665518" alt="AmazingCounters.com"></a>
                    <!-- <span id="busuanzi_container_site_pv">
					    <span id="busuanzi_value_site_pv"></span>
					</span> -->
					<!-- <a target="_blank" title="webstats program"><img alt="webstats program" 
					src="http://monster.gostats.com/bin/count/a_494843/t_4/i_38/z_0/show_hits/counter.png" 
					style="border-width:0" /></a> -->
					visitors since 2017/09/11, 
                    <span class="post-count">100.1k words altogether</span>
                </p>
                  
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://godweiyang.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->




<!-- Baidu Tongji -->

<script>
    // dynamic User by Hux
    var _baId = '46e79e71af0709a5b9106bf20cecc493';

    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>


<!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script> -->


	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>
<!-- Image to hack wechat -->
<img src="https://godweiyang.com/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work --><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>

</html>
